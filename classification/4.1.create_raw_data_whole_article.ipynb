{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccd2f2f-e25c-456a-bf48-ed763b34578e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "import textstat\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "folder_path = \"gold_standard_files\"\n",
    "output_file = \"raw_data.csv\"\n",
    "xlsx_file = \"gold_standard.xlsx\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Read the gold standard data from the Excel file\n",
    "gold_standard_df = pd.read_excel(xlsx_file)\n",
    "\n",
    "# Drop rows with NA or NaN values in the \"DocID\" column\n",
    "gold_standard_df = gold_standard_df.dropna(subset=[\"DocID\"])\n",
    "\n",
    "# Get a sorted list of XML files in the folder\n",
    "xml_files = sorted([filename for filename in os.listdir(folder_path) if filename.endswith(\".xml\")])\n",
    "\n",
    "# Function to parse the publication date and calculate the age of the concept in months\n",
    "def calculate_age_of_concept(pubdate_str):\n",
    "    publication_date = datetime.strptime(pubdate_str, \"%b %d, %Y\")\n",
    "    reference_date = datetime(1994, 9, 1)\n",
    "    return (publication_date.year - reference_date.year) * 12 + (publication_date.month - reference_date.month)\n",
    "\n",
    "# Create the CSV file and write the header\n",
    "with open(output_file, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Doc ID\", \"Institute Mentions\", \"Authors Mentions\",\n",
    "                     \"Concept Mentions (Total)\", \"Concept Mentions (Abstract)\",\n",
    "                     \"Concept Mentions (Number Of Paragraphs)\",\n",
    "                     \"Age Of The Concept In Months\",\n",
    "                     \"Average Mentions per Paragraph\", \"Percentage of Mentions in Abstract\",\n",
    "                     \"Length of the Document\", \"Keyword 1 mentions\", \"Keyword 2 mentions\",\n",
    "                     \"Keyword 3 mentions\", \"Document Type\", \"Career Stage\",\n",
    "                     \"Number of Unique Words\", \"Number of Sentences\", \n",
    "                     \"Average Sentence Length\", \"Sentiment Score\", \"Exclamation Marks Count\",\n",
    "                     \"Question Marks Count\", \"Position of First Theory Mention\", \n",
    "                     \"Contextual Phrase Count\", \"Interpretative Word Count\",\n",
    "                     \"Number of Adjectives\", \"Number of Nouns\",\n",
    "                     \"Number of Verbs\", \"Number of Adverbs\", \"Lexical Density\", \"Flesch Reading Ease\", \"Year\"])\n",
    "\n",
    "    # Iterate over each XML file in the sorted order\n",
    "    for filename in xml_files:\n",
    "        xml_file = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Extract the required information\n",
    "        doc_id = root.find(\".//doc-id\").attrib[\"id-string\"]\n",
    "        \n",
    "        # Add leading 0 to the doc ID if it is only six digits long\n",
    "        if len(doc_id) == 6:\n",
    "            doc_id = \"0\" + doc_id\n",
    "\n",
    "        text_content = ET.tostring(root, encoding=\"unicode\").lower()\n",
    "\n",
    "        author1_mentions = len(re.findall(r'\\bmurray\\b', text_content))\n",
    "        author2_mentions = len(re.findall(r'\\bherrnstein\\b', text_content))\n",
    "\n",
    "        concept_total_mentions = len(re.findall(r'\\bbell curve\\b', text_content))\n",
    "\n",
    "        abstract_text = root.find(\".//block[@class='lead_paragraph']\")\n",
    "        if abstract_text is not None:\n",
    "            abstract_content = ET.tostring(abstract_text, encoding=\"unicode\").lower()\n",
    "            concept_abstract_mentions = len(re.findall(r'\\bbell curve\\b', abstract_content))\n",
    "        else:\n",
    "            concept_abstract_mentions = 0\n",
    "\n",
    "        paragraph_mentions = 0  # Initialize paragraph mention counter\n",
    "        num_paragraphs = len(root.findall(\".//block[@class='full_text']/p\"))  # Count the number of paragraphs\n",
    "\n",
    "        # Count the mentions of \"bell curve\" and \"harvard\" in paragraphs\n",
    "        paragraph_texts = root.findall(\".//block[@class='full_text']/p\")\n",
    "        institute_mentions = 0  # Initialize Institute mention counter\n",
    "        for paragraph_text in paragraph_texts:\n",
    "            paragraph_text_lower = paragraph_text.text.lower()\n",
    "            paragraph_mentions += len(re.findall(r'\\bbell curve\\b', paragraph_text_lower))\n",
    "            institute_mentions += len(re.findall(r'\\bharvard\\b', paragraph_text_lower))\n",
    "\n",
    "        # Merge the author1 and author2 mentions\n",
    "        combined_mentions = author1_mentions + author2_mentions\n",
    "\n",
    "        # Get the publication month and year from the XML file\n",
    "        publication_month_elem = root.find(\".//meta[@name='publication_month']\")\n",
    "        publication_month = int(publication_month_elem.attrib[\"content\"]) if publication_month_elem is not None else 0\n",
    "\n",
    "        publication_year_elem = root.find(\".//meta[@name='publication_year']\")\n",
    "        publication_year = int(publication_year_elem.attrib[\"content\"]) if publication_year_elem is not None else 0\n",
    "\n",
    "        # Calculate the month distance from September 1994\n",
    "        target_date = datetime(publication_year, publication_month, 1)\n",
    "        reference_date = datetime(1994, 9, 1)\n",
    "        month_distance = (target_date.year - reference_date.year) * 12 + (target_date.month - reference_date.month)\n",
    "\n",
    "        # Extract the document type\n",
    "        document_type_label = 0\n",
    "\n",
    "        # Find the matching rows in the gold standard data based on Doc ID\n",
    "        matching_rows = gold_standard_df[gold_standard_df[\"DocID\"].astype(str).str.contains(doc_id)]\n",
    "\n",
    "        if not matching_rows.empty:\n",
    "            doc_type_from_file = matching_rows[\"documentType\"].values[0]\n",
    "            if doc_type_from_file in ['List', 'Review', 'Event']:\n",
    "                document_type_label = 1\n",
    "\n",
    "        # Find the matching rows in the gold standard data based on Doc ID\n",
    "        matching_rows = gold_standard_df[gold_standard_df[\"DocID\"].astype(str).str.contains(doc_id)]\n",
    "\n",
    "        # Extract the values from the \"IDEA CAREER 3\" column for the matching rows\n",
    "        idea_career_3_values = matching_rows[\"IDEA CAREER 3\"].astype(str).values.tolist()\n",
    "        idea_career_3_combined = \", \".join(idea_career_3_values)\n",
    "\n",
    "        # Calculate the average mentions per paragraph\n",
    "        avg_mentions_per_paragraph = paragraph_mentions / num_paragraphs\n",
    "\n",
    "        # Calculate the percentage of \"Bell Curve\" mentions in the abstract\n",
    "        percent_mentions_in_abstract = concept_abstract_mentions / concept_total_mentions if concept_total_mentions > 0 else 0\n",
    "\n",
    "        # Calculate the length of the document\n",
    "        doc_length = len(text_content)\n",
    "\n",
    "        # Count the mentions of \"I.Q./iq\"\n",
    "        keyword1_mentions = len(re.findall(r'\\bi\\.q\\.|iq\\b', text_content))\n",
    "\n",
    "        # Count the mentions of \"intelligence\"\n",
    "        keyword2_mentions = len(re.findall(r'\\bintelligence\\b', text_content))\n",
    "\n",
    "        # Count the mentions of \"race\"\n",
    "        keyword3_mentions = len(re.findall(r'\\brace\\b', text_content))\n",
    "\n",
    "        # Calculate number of unique words\n",
    "        words = text_content.split()\n",
    "        num_unique_words = len(set(words))\n",
    "\n",
    "        # Calculate number of sentences\n",
    "        sentences = nltk.sent_tokenize(text_content)\n",
    "        num_sentences = len(sentences)\n",
    "\n",
    "        # Calculate average sentence length\n",
    "        avg_sentence_length = sum(len(s.split()) for s in sentences) / num_sentences\n",
    "\n",
    "        # Calculate sentiment score\n",
    "        sentiment_score = TextBlob(text_content).sentiment.polarity\n",
    "\n",
    "        # Count number of exclamation and question marks\n",
    "        exclamation_marks_count = text_content.count('!')\n",
    "        question_marks_count = text_content.count('?')\n",
    "\n",
    "        # Determine the position of the first mention of a theory\n",
    "        position_first_theory_mention = text_content.find(\"Bell Curve\") if \"Bell Curve\" in text_content else -1\n",
    "\n",
    "        # Count the number of contextual phrases\n",
    "        contextual_phrases = [\"in this study\", \"in this research\", \"the purpose of this study\", \"this research\"]\n",
    "        contextual_phrase_count = sum(text_content.count(phrase) for phrase in contextual_phrases)\n",
    "\n",
    "        # Count the number of interpretative words\n",
    "        interpretative_words = [\"because\", \"cause\", \"effect\", \"impact\", \"result\", \"consequence\", \"reason\", \"rationale\"]\n",
    "        interpretative_word_count = sum(text_content.count(word) for word in interpretative_words)\n",
    "\n",
    "        # Count number of adjectives, nouns, verbs, and adverbs\n",
    "        tagged = pos_tag(word_tokenize(text_content))\n",
    "        counts = nltk.FreqDist(tag for (word, tag) in tagged)\n",
    "        num_adjectives = counts['JJ']\n",
    "        num_nouns = counts['NN']\n",
    "        num_verbs = counts['VB']\n",
    "        num_adverbs = counts['RB']\n",
    "\n",
    "        # Calculate lexical density\n",
    "        lexical_density = num_unique_words / len(words)\n",
    "\n",
    "        # Calculate Flesch Reading Ease\n",
    "        flesch_reading_ease = textstat.flesch_reading_ease(text_content)\n",
    "        \n",
    "        # Find the matching rows in the gold standard data based on Doc ID\n",
    "        matching_rows = gold_standard_df[gold_standard_df[\"DocID\"].astype(str).str.contains(doc_id)]\n",
    "\n",
    "        # Get the 'year' value from the gold standard DataFrame\n",
    "        year = matching_rows[\"year\"].values[0] if \"year\" in matching_rows else None  \n",
    "        writer.writerow([doc_id, institute_mentions, combined_mentions, concept_total_mentions,\n",
    "                         concept_abstract_mentions, paragraph_mentions, month_distance,\n",
    "                         avg_mentions_per_paragraph, percent_mentions_in_abstract, doc_length,\n",
    "                         keyword1_mentions, keyword2_mentions, keyword3_mentions,\n",
    "                         document_type_label, idea_career_3_combined, num_unique_words,\n",
    "                         num_sentences, avg_sentence_length, sentiment_score,\n",
    "                         exclamation_marks_count, question_marks_count, position_first_theory_mention,\n",
    "                         contextual_phrase_count, interpretative_word_count, num_adjectives, num_nouns,\n",
    "                         num_verbs, num_adverbs, lexical_density, flesch_reading_ease, year])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1985e-a202-4aa0-b8d1-57ce06ff5338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
